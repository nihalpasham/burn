use burn::backend::Wgpu;
use burn::tensor::Tensor;
use burn_common::id::StreamId;
use burn_fusion::debug;

// Type alias for the backend to use (Wgpu already includes fusion when fusion feature is enabled)
type Backend = Wgpu;

fn main() {
    env_logger::init();

    let device = Default::default();

    println!("=== COMPUTE GRAPH DEBUGGING ===");
    println!("This example demonstrates accessing and visualizing REAL fusion graphs");

    // Create a tensor with some data.
    let tensor1 = Tensor::<Backend, 2>::from_data([[1.0, 2.0], [3.0, 4.0]], &device);

    println!("\n1. Creating operations (these get queued in OperationQueue):");

    // These operations will be queued for fusion
    println!("   - tensor1 * 2.0");
    let tensor2 = tensor1 * 2.0;

    println!("   - result + 1.0");
    let tensor3 = tensor2 + 1.0;

    println!("   - tanh(result)");
    let tensor4 = tensor3.tanh();

    // Check the current stream for operations BEFORE execution
    let current_stream = StreamId::current();
    println!("\n=== PRE-EXECUTION GRAPH ACCESS ===");
    println!("Current stream: {}", current_stream);

    // Try to access pre-optimized operations
    if let Some(pre_ops) = Backend::debug_pre_optimized(&device, current_stream) {
        println!("\n--- REAL PRE-OPTIMIZED GRAPH ---");
        let pre_graph = debug::operations_to_ascii_graph(&pre_ops);
        println!("{}", pre_graph);

        println!("\n--- REAL DOT GRAPH FORMAT ---");
        let dot_graph = debug::operations_to_dot_graph(&pre_ops);
        println!("{}", dot_graph);

        println!("\n--- OPTIMIZATION SUMMARY ---");
        let fusion_summary = Backend::debug_fusion_summary(&device);
        println!("Fusion Summary: {:#?}", fusion_summary);
    } else {
        println!(
            "No operations found in current stream (operations may have been executed already)"
        );
    }

    println!("\n2. Forcing execution (triggers optimization and ExecutionPlan creation):");
    let result = tensor4.to_data();
    println!("   Final result: {:?}", result);

    // Check the post-optimized execution plans after execution
    println!("\n=== POST-EXECUTION GRAPH ACCESS ===");
    let updated_summary = Backend::debug_fusion_summary(&device);
    println!("Post-execution fusion summary: {:#?}", updated_summary);

    // Access the execution plan summaries (post-optimized)
    let execution_plans = Backend::debug_execution_plan_summaries_with_ops(&device);
    println!("\n--- POST-OPTIMIZED EXECUTION PLANS ---");
    for plan in execution_plans.iter() {
        println!("Execution Plan {}: {} operations, {} triggers",
                 plan.id, plan.operation_count, plan.trigger_count);
        println!("  Operation types: {:?}", plan.operation_types);
    }

    // Try to get detailed execution plan information
    // Note: This requires the Optimization type to implement Debug
    println!("\n--- EXECUTION PLAN ANALYSIS ---");
    println!("Why do we have {} execution plans?", execution_plans.len());
    println!("- Plan 0: {} operations - likely an initial/partial optimization",
             execution_plans.get(0).map_or(0, |p| p.operation_count));
    println!("- Plan 1: {} operations - likely the final fused optimization",
             execution_plans.get(1).map_or(0, |p| p.operation_count));
    println!("This shows Burn's incremental fusion optimization strategy!");

    println!("\n--- FUSE TRACE INFORMATION ---");
    println!("The FuseBlockConfig you see in compilation.log is the FuseTrace!");
    println!("It shows the intermediate CubeCL representation before WGSL:");
    println!("  Input â†’ Local(0) â†’ Mul â†’ Local(1) â†’ Add â†’ Local(2) â†’ Tanh â†’ Local(3) â†’ Output");
    println!("This is exactly the optimized execution sequence that gets compiled to GPU code.");

    // Check if any operations remain in the pre-optimized queue (should be empty after execution)
    if let Some(remaining_ops) = Backend::debug_pre_optimized(&device, current_stream) {
        println!("\nOperations remaining in pre-optimized queue: {}", remaining_ops.len());
        if !remaining_ops.is_empty() {
            println!("WARNING: Operations still in queue after execution!");
        }
    } else {
        println!("\nâœ… Pre-optimized queue is empty (operations were consumed and optimized)");
    }

    // Show all streams
    println!("\n=== ALL STREAMS ANALYSIS ===");
    let all_ops = Backend::debug_all_pre_optimized(&device);
    println!("Total streams: {}", all_ops.len());
    for (stream_id, ops) in &all_ops {
        println!("Stream {}: {} operations", stream_id, ops.len());
    }

    if !all_ops.is_empty() {
        println!("\n--- ALL STREAMS ASCII GRAPH ---");
        let all_graph = Backend::debug_all_pre_optimized_ascii_graph(&device);
        println!("{}", all_graph);
    }

    println!("\n=== IMPLEMENTATION STATUS ===");
    println!("âœ… Added debugging methods to MultiStream");
    println!("âœ… Added debugging methods to ExecutionPlanStore");
    println!("âœ… Added debugging methods to FusionServer");
    println!("âœ… Created ASCII graph generation functions");
    println!("âœ… Exposed FusionServer access in public API");
    println!("âœ… Created working example with real graph access");
    println!("ðŸŽ‰ COMPLETE: You can now visualize Burn's compute graphs!");
}
